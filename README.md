# Competitions repository

Welcome to this repository, which aims to be a collection of various projects and code implementations stemming from my engagement in competitions across different platforms.

1. [AI Village Capture the Flag @ DEFCON31](https://www.kaggle.com/competitions/ai-village-capture-the-flag-defcon31)

27 hand-crafted machine learning security challenges to find flags, solve puzzles, and gain hands-on experience with concepts of AI security and safety.\
I was able to secure the 76th place out of 1360 people competing (top 6%), [on Kaggle](https://www.kaggle.com/code/jacoporepossi/defcon31-ctf-top-6-22-flags-solutions) I published my solutions

2. [AI Assistants for Data Tasks with Gemma](https://www.kaggle.com/competitions/data-assistants-with-gemma)

Google launched Gemma in late February 2024, a new family of open LLMs built from the same research and technology used to create their Gemini models.
The competition challenged the community to demonstrate how to use Gemma to accomplish one or more data science oriented tasks and I chose text summarization.\
My final choice focused on the complex world of text summarization and my notebook can be found on [Kaggle](https://www.kaggle.com/code/jacoporepossi/text-summarization-with-gemma).

3. [HackAPrompt - Trick Large Language Models](https://www.hackaprompt.com/track/hackaprompt_1.0_competition)

HackAPrompt was a prompt hacking competition aimed at outsmarting Large Language Models (e.g. LLAMA, GPT-3.5) where participants attempted to hack through many prompt hacking defenses as possible.\
I partecipated with a colleague, securing the 32nd place out of 476 teams (top 7%).\
The detailed writeup of my solutions can be found [here](https://jacoporepossi.github.io/learningq/posts/2023-06-01-prompt-hacking/), where I explore the different techniques I used to secure the 32nd place out of 476 teams (top 7%).

4. [LLM CTF @ SaTML 2024](https://ctf.spylab.ai/)

In this LLM prompt hacking competition, participants assumed the roles of defenders and/or attackers, that is:

- Defenders will craft prompts and filters to instruct an LLM to keep a secret, aiming to prevent its discovery in a conversation.
- Attackers will design strategies to extract the secret from the LLM, circumventing the defenderâ€™s safeguards.

Despite spending a limited amount of time, my defense approach ranked 14th with an 85% filtering rate, and my attack strategy had a 33% success rate. Check out the [full write-up](hhttps://jacoporepossi.github.io/learningq/posts/2024-06-29-satml-llm-ctf/) for a detailed overview of my findings.

5. [HackAPrompt 2.0 - CBRNE](https://www.hackaprompt.com/track/cbrne_practice)

Second edition of the HackAPrompt, where participants were presented with 15 different challenges in which they had to convince LLMs to elicit information about chemical, biological, radiological, nuclear, and explosive harms (CBRNE).\
I partecipated with a colleague, securing the 4th place out of 50 teams. Here's the [full write-up](https://jacoporepossi.github.io/learningq/posts/2025-06-22-prompt-hacking-cbrne/)